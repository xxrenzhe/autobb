/**
 * ä½¿ç”¨ Vertex AI è°ƒç”¨ Gemini API
 * ä¼˜åŠ¿ï¼š
 * 1. æ— éœ€ä»£ç†ï¼Œç›´æ¥é€šè¿‡ Service Account è®¤è¯
 * 2. ä¼ä¸šçº§ç¨³å®šæ€§å’Œ SLA
 * 3. æ›´å¥½çš„é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶
 */

import { VertexAI, GenerativeModel, HarmCategory, HarmBlockThreshold } from '@google-cloud/vertexai'
import * as path from 'path'

// å•ä¾‹ VertexAI å®¢æˆ·ç«¯å’Œå½“å‰é…ç½®
let vertexAI: VertexAI | null = null
let currentConfig: {
  projectId: string
  location: string
  credentialsPath: string
} | null = null

/**
 * é‡ç½® VertexAI å®¢æˆ·ç«¯ï¼ˆå½“é…ç½®å˜æ›´æ—¶è°ƒç”¨ï¼‰
 */
export function resetVertexAIClient(): void {
  vertexAI = null
  currentConfig = null
  console.log('ğŸ”„ Vertex AI å®¢æˆ·ç«¯å·²é‡ç½®')
}

/**
 * è·å– VertexAI å®¢æˆ·ç«¯ï¼ˆå¸¦é…ç½®å˜æ›´æ£€æµ‹ï¼‰
 * æ¯æ¬¡è°ƒç”¨éƒ½æ£€æŸ¥å½“å‰ç¯å¢ƒå˜é‡ï¼Œå¦‚æœé…ç½®å˜äº†å°±é‡æ–°åˆå§‹åŒ–
 */
function getVertexAI(): VertexAI {
  // è·å–å½“å‰ç¯å¢ƒå˜é‡é…ç½®ï¼ˆæ¯æ¬¡éƒ½è¯»å–æœ€æ–°å€¼ï¼‰
  const projectId = process.env.GCP_PROJECT_ID
  const location = process.env.GCP_LOCATION || 'us-central1'
  const credentialsPath = process.env.GOOGLE_APPLICATION_CREDENTIALS ||
    path.join(process.cwd(), 'docs/secrets/gcp_autoads_dev.json')

  // æ£€æŸ¥æ˜¯å¦éœ€è¦é‡æ–°åˆå§‹åŒ–ï¼ˆé…ç½®å˜æ›´æˆ–é¦–æ¬¡åˆå§‹åŒ–ï¼‰
  const needsReinit = !vertexAI || !currentConfig ||
    currentConfig.projectId !== projectId ||
    currentConfig.location !== location ||
    currentConfig.credentialsPath !== credentialsPath

  if (needsReinit) {
    if (!projectId) {
      throw new Error('Vertex AIé…ç½®é”™è¯¯ï¼šç¼ºå°‘GCP_PROJECT_IDç¯å¢ƒå˜é‡')
    }

    if (!credentialsPath) {
      throw new Error('Vertex AIé…ç½®é”™è¯¯ï¼šç¼ºå°‘GOOGLE_APPLICATION_CREDENTIALSç¯å¢ƒå˜é‡')
    }

    console.log(`ğŸ”§ åˆå§‹åŒ– Vertex AI å®¢æˆ·ç«¯...`)
    console.log(`   Project: ${projectId}`)
    console.log(`   Location: ${location}`)
    console.log(`   Credentials: ${credentialsPath}`)

    // ç›´æ¥ä¼ é€’å‡­è¯æ–‡ä»¶è·¯å¾„ï¼Œè€Œä¸æ˜¯ä¾èµ–ç¯å¢ƒå˜é‡
    // è¿™æ ·å¯ä»¥ç¡®ä¿åœ¨è¿è¡Œæ—¶åŠ¨æ€è®¾ç½®çš„å‡­è¯è¢«æ­£ç¡®ä½¿ç”¨
    vertexAI = new VertexAI({
      project: projectId,
      location: location,
      googleAuthOptions: {
        keyFilename: credentialsPath,
      },
    })

    // ä¿å­˜å½“å‰é…ç½®ç”¨äºåç»­æ¯”è¾ƒ
    currentConfig = {
      projectId,
      location,
      credentialsPath,
    }

    console.log('âœ“ Vertex AI å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ')
  }

  // TypeScriptç¡®ä¿vertexAIåœ¨æ­¤å¤„énull
  if (!vertexAI) {
    throw new Error('Vertex AIå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥')
  }

  return vertexAI
}

/**
 * è·å–ç”Ÿæˆæ¨¡å‹
 */
function getGenerativeModel(modelName: string): GenerativeModel {
  const client = getVertexAI()

  return client.getGenerativeModel({
    model: modelName,
    safetySettings: [
      {
        category: HarmCategory.HARM_CATEGORY_HATE_SPEECH,
        threshold: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
      },
      {
        category: HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,
        threshold: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
      },
      {
        category: HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,
        threshold: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
      },
      {
        category: HarmCategory.HARM_CATEGORY_HARASSMENT,
        threshold: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
      },
    ],
  })
}

/**
 * å¸¦é‡è¯•çš„å»¶è¿Ÿå‡½æ•°
 */
async function delay(ms: number): Promise<void> {
  return new Promise(resolve => setTimeout(resolve, ms))
}

/**
 * è°ƒç”¨ Vertex AI Gemini API ç”Ÿæˆå†…å®¹ï¼ˆå¸¦è‡ªåŠ¨é™çº§å’Œé‡è¯•ï¼‰
 *
 * @param params - ç”Ÿæˆå‚æ•°
 * @param params.model - æ¨¡å‹åç§°ï¼Œé»˜è®¤ 'gemini-2.5-pro'
 *   æ”¯æŒçš„æ¨¡å‹ï¼š
 *   - gemini-2.5-pro (ç¨³å®šç‰ˆï¼Œæ¨è)
 *   - gemini-2.5-flash (å¿«é€Ÿç‰ˆ)
 *   - gemini-2.5-flash-lite (è½»é‡ç‰ˆ)
 *   - gemini-3-pro-preview-11-2025 (é¢„è§ˆç‰ˆï¼Œæœ€æ–°)
 * @param params.prompt - æç¤ºè¯
 * @param params.temperature - æ¸©åº¦å‚æ•°ï¼Œé»˜è®¤ 0.7
 * @param params.maxOutputTokens - æœ€å¤§è¾“å‡ºtokensï¼Œé»˜è®¤ 2048
 * @returns ç”Ÿæˆçš„æ–‡æœ¬å†…å®¹
 */
export async function generateContent(params: {
  model?: string
  prompt: string
  temperature?: number
  maxOutputTokens?: number
}): Promise<string> {
  const {
    model = 'gemini-2.5-pro',
    prompt,
    temperature = 0.7,
    maxOutputTokens = 2048,
  } = params

  const maxRetries = 3
  let lastError: Error | null = null

  // å°è¯•ä¸»æ¨¡å‹
  for (let attempt = 1; attempt <= maxRetries; attempt++) {
    try {
      console.log(`ğŸ¤– è°ƒç”¨ Vertex AI: ${model} (å°è¯• ${attempt}/${maxRetries})`)

      const generativeModel = getGenerativeModel(model)

      const result = await generativeModel.generateContent({
        contents: [
          {
            role: 'user',
            parts: [{ text: prompt }],
          },
        ],
        generationConfig: {
          temperature,
          maxOutputTokens,
        },
      })

      const response = result.response

      if (!response.candidates || response.candidates.length === 0) {
        throw new Error('Vertex AI è¿”å›äº†ç©ºå“åº”')
      }

      const candidate = response.candidates[0]

      // æ£€æŸ¥finishReasonä»¥è¯Šæ–­æˆªæ–­é—®é¢˜
      if (candidate.finishReason && candidate.finishReason !== 'STOP') {
        console.warn(`âš ï¸ Vertex AI è¾“å‡ºè¢«æˆªæ–­: ${candidate.finishReason}`)
        if (candidate.finishReason === 'MAX_TOKENS') {
          console.warn(`   åŸå› : è¾¾åˆ°maxOutputTokensé™åˆ¶ (å½“å‰: ${maxOutputTokens})`)
          console.warn(`   âš ï¸  å»ºè®®: å¢åŠ maxOutputTokensæˆ–ç²¾ç®€prompt`)
        } else if (candidate.finishReason === 'SAFETY') {
          console.warn(`   åŸå› : å®‰å…¨è¿‡æ»¤è§¦å‘`)
          if (candidate.safetyRatings) {
            console.warn(`   å®‰å…¨è¯„çº§:`, JSON.stringify(candidate.safetyRatings))
          }
        }
        // æ³¨æ„ï¼šå³ä½¿è¢«æˆªæ–­ï¼Œä»ç„¶å°è¯•è¿”å›éƒ¨åˆ†å†…å®¹ï¼ˆä¸‹æ¸¸å¯ä»¥å°è¯•è§£æï¼‰
      }

      if (!candidate.content || !candidate.content.parts || candidate.content.parts.length === 0) {
        throw new Error('Vertex AI å“åº”ä¸­æ²¡æœ‰å†…å®¹')
      }

      const text = candidate.content.parts
        .map(part => part.text || '')
        .join('')

      if (!text) {
        throw new Error('Vertex AI è¿”å›äº†ç©ºæ–‡æœ¬')
      }

      console.log(`âœ“ Vertex AI è°ƒç”¨æˆåŠŸï¼Œè¿”å› ${text.length} å­—ç¬¦`)

      // è®°å½•tokenä½¿ç”¨æƒ…å†µ
      if (response.usageMetadata) {
        console.log(`   Tokenä½¿ç”¨: prompt=${response.usageMetadata.promptTokenCount}, ` +
          `output=${response.usageMetadata.candidatesTokenCount}, ` +
          `total=${response.usageMetadata.totalTokenCount}`)
      }

      return text
    } catch (error: any) {
      lastError = error
      console.warn(`âš ï¸ Vertex AI è°ƒç”¨å¤±è´¥ (å°è¯• ${attempt}/${maxRetries}): ${error.message}`)
      console.error('å®Œæ•´é”™è¯¯ä¿¡æ¯:', JSON.stringify({
        message: error.message,
        code: error.code,
        status: error.status,
        statusCode: error.statusCode,
        details: error.details,
        stack: error.stack?.split('\n').slice(0, 3).join('\n')
      }, null, 2))

      // æ£€æŸ¥æ˜¯å¦æ˜¯å¯é‡è¯•çš„é”™è¯¯
      const isRetryable =
        error.message?.includes('503') ||
        error.message?.includes('overload') ||
        error.message?.includes('RESOURCE_EXHAUSTED') ||
        error.message?.includes('UNAVAILABLE') ||
        error.message?.includes('DEADLINE_EXCEEDED') ||
        error.message?.includes('timeout') ||
        error.code === 'ECONNRESET' ||
        error.code === 'ETIMEDOUT'

      if (isRetryable && attempt < maxRetries) {
        const waitTime = Math.pow(2, attempt) * 1000 // æŒ‡æ•°é€€é¿: 2s, 4s, 8s
        console.log(`   ç­‰å¾… ${waitTime / 1000}s åé‡è¯•...`)
        await delay(waitTime)
        continue
      }

      // ä¸å¯é‡è¯•æˆ–å·²ç”¨å®Œé‡è¯•æ¬¡æ•°
      break
    }
  }

  // ä¸»æ¨¡å‹å¤±è´¥ï¼Œå°è¯•é™çº§åˆ° flash æ¨¡å‹
  if (model.includes('pro')) {
    const fallbackModel = 'gemini-2.5-flash'
    console.warn(`âš ï¸ ${model} è°ƒç”¨å¤±è´¥ï¼Œé™çº§åˆ° ${fallbackModel}`)

    for (let attempt = 1; attempt <= maxRetries; attempt++) {
      try {
        console.log(`ğŸ¤– è°ƒç”¨ Vertex AI (é™çº§): ${fallbackModel} (å°è¯• ${attempt}/${maxRetries})`)

        const generativeModel = getGenerativeModel(fallbackModel)

        const result = await generativeModel.generateContent({
          contents: [
            {
              role: 'user',
              parts: [{ text: prompt }],
            },
          ],
          generationConfig: {
            temperature,
            maxOutputTokens,
          },
        })

        const response = result.response

        if (!response.candidates || response.candidates.length === 0) {
          throw new Error('Vertex AI (fallback) è¿”å›äº†ç©ºå“åº”')
        }

        const candidate = response.candidates[0]

        if (!candidate.content || !candidate.content.parts || candidate.content.parts.length === 0) {
          throw new Error('Vertex AI (fallback) å“åº”ä¸­æ²¡æœ‰å†…å®¹')
        }

        const text = candidate.content.parts
          .map(part => part.text || '')
          .join('')

        if (!text) {
          throw new Error('Vertex AI (fallback) è¿”å›äº†ç©ºæ–‡æœ¬')
        }

        console.log(`âœ“ Vertex AI (fallback: ${fallbackModel}) è°ƒç”¨æˆåŠŸï¼Œè¿”å› ${text.length} å­—ç¬¦`)

        return text
      } catch (fallbackError: any) {
        console.warn(`âš ï¸ Vertex AI (fallback) è°ƒç”¨å¤±è´¥ (å°è¯• ${attempt}/${maxRetries}): ${fallbackError.message}`)

        if (attempt < maxRetries) {
          const waitTime = Math.pow(2, attempt) * 1000
          console.log(`   ç­‰å¾… ${waitTime / 1000}s åé‡è¯•...`)
          await delay(waitTime)
          continue
        }

        // é™çº§æ¨¡å‹ä¹Ÿå¤±è´¥
        throw new Error(
          `Vertex AI è°ƒç”¨å¤±è´¥ã€‚ä¸»æ¨¡å‹(${model})é”™è¯¯: ${lastError?.message}ã€‚` +
          `é™çº§æ¨¡å‹(${fallbackModel})é”™è¯¯: ${fallbackError.message}`
        )
      }
    }
  }

  // æ‰€æœ‰å°è¯•éƒ½å¤±è´¥
  throw new Error(`Vertex AI è°ƒç”¨å¤±è´¥: ${lastError?.message}`)
}

/**
 * æ£€æŸ¥ Vertex AI è¿æ¥çŠ¶æ€
 */
export async function checkVertexAIConnection(): Promise<boolean> {
  try {
    const model = getGenerativeModel('gemini-2.5-flash')
    const result = await model.generateContent({
      contents: [
        {
          role: 'user',
          parts: [{ text: 'Hello' }],
        },
      ],
      generationConfig: {
        maxOutputTokens: 10,
      },
    })

    return !!(result.response.candidates && result.response.candidates.length > 0)
  } catch (error) {
    console.error('Vertex AI è¿æ¥æ£€æŸ¥å¤±è´¥:', error)
    return false
  }
}
